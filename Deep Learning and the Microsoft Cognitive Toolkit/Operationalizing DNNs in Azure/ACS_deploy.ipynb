{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploying CNTK deep learning models as real-time micro-services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://github.com/ilkarman/Blog/blob/master/rndm/ACS%20Deploy.ipynb , https://github.com/Azure/Spark-Operationalization-On-Azure/blob/master/samples/cntk/tutorials/realtime/image_classification.md and https://github.com/Azure-Samples/hdinsight-pyspark-cntk-integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "Deep learning models are trained for a variety of tasks, from image classification to translation. Often times, there is a need to perform real time scoring of unseen data. \n",
    "\n",
    "The Azure Machine Learning CLI is a tool that wraps the APIs of Azure to deploy a VM scale set backed by Marathon and allows the deployment of deep learning models on docker containers right from the command line.\n",
    "\n",
    "In this tutorial we will demonstrate the deployment of an Image Classification service on docker containers using  a pre-trained CNTK Resnet_152 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the AML CLI dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install azuremlcli asyncio aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install azure-cli -I --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating ssh key pair and saving it in the .library for re-use between containers\n",
    "import os\n",
    "if not os.path.exists('/home/nbuser/.ssh/id_rsa'):\n",
    "    !ssh-keygen -t rsa -b 2048 -N \"\" -f ~/.ssh/id_rsa\n",
    "print('Private key id_rsa:')\n",
    "!cat ~/.ssh/id_rsa\n",
    "print('Public key id_rsa.pub:')\n",
    "!cat ~/.ssh/id_rsa.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the private key and the public key, as you will need them to access your cluster if you plan to keep longer than the length of this tutorial. Azure notebooks run in a container that can get restarted after a period of inactivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the ACS environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login into your azure account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select a non-default subscription to use, uncomment and replace the value of `subscription` with the name of the subcsription you want to use, copied from the output of the previous command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subscription = \"<YOUR_SUBSCRIPTION_NAME_HERE>\"\n",
    "subscription = \"'\" + subscription + \"'\"\n",
    "!az account set --subscription $subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the aml environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "name = \"aiimmersion{}\".format(str(uuid.uuid4())[:8])\n",
    "\n",
    "# Creating the environment\n",
    "!aml env setup --name $name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the deployment key found in the command at the end the following paragraph into **ACS_deployment_key**:\n",
    "\n",
    "```\n",
    "Started ACS deployment. Please note that it can take up to 15 minutes to complete the deployment.\n",
    "You can continue to work with aml in local mode while the ACS is being provisioned.\n",
    "To check the status of the deployment, run the following command:\n",
    "aml env setup -s XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ACS_deployment_key = \"<YOUR_ACS_DEPLOYMENT_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"YOUR_ACS_DEPLOYMENT_KEY\" in ACS_deployment_key:\n",
    "    print(\"/!\\ STOP /!\\ You need to modify the value of ACS_deployment_key, please follow the above instructions\")\n",
    "else:\n",
    "    print(\"You are good to go :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the cluster deployment status, it should be **Running** which means the deployment is still running and that the cluster is **NOT YET** deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aml env setup -s $ACS_deployment_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the AML environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ~/.amlenvrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure Notebook environment does not persist environment variables beyond current shell execution \n",
    "This little trick sources first the environment variables before running the AML cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Moving the original aml to aml_orig\n",
    "aml_path = !which aml\n",
    "aml_path = aml_path[0]\n",
    "aml_path_orig = aml_path + \"_orig\"\n",
    "if not os.path.exists(aml_path_orig):\n",
    "    !mv $aml_path $aml_path_orig\n",
    "\n",
    "# Writing a new script to source the env variables\n",
    "# before running the aml CLI\n",
    "script = \"\"\"\n",
    "#!/bin/sh \n",
    "touch ~/.amlenvrc\n",
    ". ~/.amlenvrc\n",
    "export no_proxy=127.0.0.1\n",
    "{} $@\n",
    "\"\"\".format(aml_path_orig)\n",
    "with open(aml_path, 'w') as f:\n",
    "    f.write(script)\n",
    "\n",
    "# Setting the permission to executable\n",
    "!chmod 755 $aml_path\n",
    "\n",
    "!aml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the **ImageNet** CNTK pre-trained model using the ResNet_152 architecture and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget \"https://migonzastorage.blob.core.windows.net/deep-learning/models/cntk/imagenet/ResNet_152.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget \"https://ikcompuvision.blob.core.windows.net/acs/synset.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the driver file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The driver file needs to implement 2 functions, **init()** and **run(inputString)** \n",
    "In the **init()** function we load the model in memory.\n",
    "In the **run(inputString)** we parse the input image and process it through the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile driver.py\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import timeit as t\n",
    "import urllib.request\n",
    "import base64\n",
    "from cntk import load_model, combine\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "\n",
    "logger = logging.getLogger(\"cntk_svc_logger\")\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "trainedModel = None\n",
    "mem_after_init = None\n",
    "labelLookup = None\n",
    "topResult = 3\n",
    "\n",
    "def aml_cli_get_sample_request():\n",
    "    return '{\"input\": [\"base64Image\"]}'\n",
    "\n",
    "def init():\n",
    "    global trainedModel, labelLookup, mem_after_init\n",
    "\n",
    "    # Load the model from disk and perform evals\n",
    "    # Load labels txt\n",
    "    with open('synset.txt', 'r') as f:\n",
    "        labelLookup = [l.rstrip() for l in f]\n",
    "    \n",
    "    # The pre-trained model was trained using brainscript\n",
    "    # Loading is not we need the right index \n",
    "    # See https://github.com/Microsoft/CNTK/wiki/How-do-I-Evaluate-models-in-Python\n",
    "    # Load model and load the model from brainscript (3rd index)\n",
    "    trainedModel = load_model('ResNet_152.model')\n",
    "    trainedModel = combine([trainedModel.outputs[3].owner])\n",
    "\n",
    "def run(inputString):\n",
    "\n",
    "    start = t.default_timer()\n",
    "\n",
    "    images = json.loads(inputString)\n",
    "    result = []\n",
    "    totalPreprocessTime = 0\n",
    "    totalEvalTime = 0\n",
    "    totalResultPrepTime = 0\n",
    "\n",
    "    for base64ImgString in images:\n",
    "\n",
    "        if base64ImgString.startswith('b\\''):\n",
    "            base64ImgString = base64ImgString[2:-1]\n",
    "        base64Img = base64ImgString.encode('utf-8')\n",
    "\n",
    "        # Preprocess the input data\n",
    "        startPreprocess = t.default_timer()\n",
    "        decoded_img = base64.b64decode(base64Img)\n",
    "        img_buffer = BytesIO(decoded_img)\n",
    "        # Load image with PIL (RGB)\n",
    "        pil_img = Image.open(img_buffer).convert('RGB')\n",
    "        pil_img = ImageOps.fit(pil_img, (224, 224), Image.ANTIALIAS)\n",
    "        rgb_image = np.array(pil_img, dtype=np.float32)\n",
    "        # Resnet trained with BGR\n",
    "        bgr_image = rgb_image[..., [2, 1, 0]]\n",
    "        imageData = np.ascontiguousarray(np.rollaxis(bgr_image, 2))\n",
    "\n",
    "        endPreprocess = t.default_timer()\n",
    "        totalPreprocessTime += endPreprocess - startPreprocess\n",
    "\n",
    "        # Evaluate the model using the input data\n",
    "        startEval = t.default_timer()\n",
    "        imgPredictions = np.squeeze(trainedModel.eval(\n",
    "            {trainedModel.arguments[0]: [imageData]}))\n",
    "        endEval = t.default_timer()\n",
    "        totalEvalTime += endEval - startEval\n",
    "\n",
    "        # Only return top 3 predictions\n",
    "        startResultPrep = t.default_timer()\n",
    "        resultIndices = (-np.array(imgPredictions)).argsort()[:topResult]\n",
    "        imgTopPredictions = []\n",
    "        for i in range(topResult):\n",
    "            imgTopPredictions.append(\n",
    "                (labelLookup[resultIndices[i]], imgPredictions[resultIndices[i]] * 100))\n",
    "        endResultPrep = t.default_timer()\n",
    "        result.append(imgTopPredictions)\n",
    "\n",
    "        totalResultPrepTime += endResultPrep - startResultPrep\n",
    "\n",
    "    end = t.default_timer()\n",
    "\n",
    "    logger.info(\"Predictions: {0}\".format(result))\n",
    "    logger.info(\"Predictions took {0} ms\".format(\n",
    "        round((end - start) * 1000, 2)))\n",
    "    logger.info(\"Time distribution: preprocess={0} ms, eval={1} ms, resultPrep = {2} ms\".format(round(\n",
    "        totalPreprocessTime * 1000, 2), round(totalEvalTime * 1000, 2), round(totalResultPrepTime * 1000, 2)))\n",
    "\n",
    "    actualWorkTime = round(\n",
    "        (totalPreprocessTime + totalEvalTime + totalResultPrepTime) * 1000, 2)\n",
    "    return (result, 'Computed in {0} ms'.format(actualWorkTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the realtime service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command until the deployment is completed, and **not `Running`**\n",
    "It can take up to 15 minutes to complete the cluster provisionning\n",
    "\n",
    "If it is still **Running**, re-run this command until you don't see **Running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aml env setup -s $ACS_deployment_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the deployment of the cluster is completed, switch to cluster mode, **otherwise, wait**.\n",
    "\n",
    "Make sure to have **AML_ACS_MASTER** and **AML_ACS_AGENT** env variable specified in the configuration file.\n",
    "Otherwise **it probably means your cluster deployment is still running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ~/.amlenvrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the fingerprint of the master using the env variable AML_ACS_MASTER in the list of known_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! . ~/.amlenvrc && ssh-keyscan -p 2200 $AML_ACS_MASTER >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching the environment to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ~/.amlenvrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo '\\n' | aml env cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the realtime service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "service_name = 'cntkservice'\n",
    "!aml service create realtime -r cntk-py -f driver.py -m ResNet_152.model -d synset.txt -n $service_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aml service view realtime $service_name -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **/!\\** **/!\\** **/!\\** Update the **CLUSTER_SCORING_URL** with the URL you obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLUSTER_SCORING_URL = \"http://YOUR_SCORING_URL:9091/score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"YOUR_SCORING_URL\" in CLUSTER_SCORING_URL:\n",
    "    print(\"/!\\ STOP /!\\ You need to modify the value above to contain your scoring url\")\n",
    "else:\n",
    "    print(\"You are good to go! :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score images against the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_img_to_json_img(url):\n",
    "    bytfile = BytesIO(urllib.request.urlopen(url).read())\n",
    "    img = Image.open(bytfile).convert('RGB')  # 3 Channels\n",
    "    img = ImageOps.fit(img, (224, 224), Image.ANTIALIAS)  # Fixed size \n",
    "    plt.imshow(img)\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'PNG')\n",
    "    imgio.seek(0)\n",
    "    dataimg = base64.b64encode(imgio.read())\n",
    "    return json.dumps(\n",
    "        {'input':'[\\\"{0}\\\"]'.format(dataimg.decode('utf-8'))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEADERS = {'content-type': 'application/json',\n",
    "           'X-Marathon-App-Id': '/{}'.format(service_name)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own image by uploading the image using the `Data` button in the notebook toolbar then using the name of the image, for example `image.png` instead of the URL below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_url = 'http://thomasdelteillondon.blob.core.windows.net/public/shuttle.jpg'\n",
    "jsondata = url_img_to_json_img(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posting the actual request to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.post(CLUSTER_SCORING_URL, data=jsondata, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(res.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing\n",
    "Let see how fast it can process requests in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def fetch(url, session):\n",
    "    async with session.post(url, headers={\n",
    "        \"content-type\":\"application/json\",\n",
    "        \"X-Marathon-App-Id\":\"/{}\".format(service_name)\n",
    "    }, data=jsondata) as response:\n",
    "        date = response.headers.get(\"DATE\")\n",
    "        #print(\"{}:{}\".format(date, response.url))\n",
    "        return await response.read()\n",
    "\n",
    "\n",
    "async def bound_fetch(sem, url, session):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        await fetch(url, session)\n",
    "\n",
    "\n",
    "async def run(r):\n",
    "    url = CLUSTER_SCORING_URL\n",
    "    tasks = []\n",
    "    # create instance of Semaphore\n",
    "    sem = asyncio.Semaphore(1000)\n",
    "\n",
    "    # Create client session that will ensure we dont open new connection\n",
    "    # per each request.\n",
    "    async with ClientSession() as session:\n",
    "        for i in range(r):\n",
    "            # pass Semaphore and session to every GET request\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = asyncio.gather(*tasks)\n",
    "        await responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "number = 30\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "future = asyncio.ensure_future(run(number))\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Delete the resource group, this can take up to several minutes without showing any output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resource_group = name+\"rg\"\n",
    "!az group delete --yes -n $resource_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ps aux | grep ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ~/.ssh/acs_id_rsa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
