{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How to Quickly Start Competing in the Kaggle Data Science Bowl 2017 with CNTK and LightGBM\n",
    "\n",
    "In this notebook, we share a baseline script that allows anyone interested in participating in the [Data Science Bowl Lung Cancer Detection Competition](https://www.kaggle.com/c/data-science-bowl-2017) to create the first submission quickly. We first extract features from the CT scan images of lungs using a pretrained convolutional neural network (CNN) implemented on [CNTK](https://github.com/Microsoft/CNTK/wiki), followed by running a boosted tree classifier implemented on [LightGBM](https://github.com/Microsoft/LightGBM).  Both CNTK and LightGBM have been shown to have excellent training speed in a range of tasks (see, for examples, [this paper](https://arxiv.org/abs/1608.07249) for CNTK and [this summary](https://github.com/Microsoft/LightGBM/wiki/Experiments#comparison-experiment) for LightGBM), and this should help participants iterate on their models quickly.  Furthermore, we use [GPU acceleration available on Azure Data Science Virtual Machines](http://aka.ms/dsvm/deeplearning) to speed up computations in CNN featurization.  \n",
    "\n",
    "With these three tools, one can achieve a **score of 0.55979** on the leaderboard within approximately **one hour** (excluding data download and virtual machine startup time). \n",
    "\n",
    "\n",
    "This work is also published as a [blog in Technet](https://blogs.technet.microsoft.com/machinelearning/2017/02/17/quick-start-guide-to-the-data-science-bowl-lung-cancer-detection-challenge-using-deep-learning-microsoft-cognitive-toolkit-and-azure-gpu-vms/), as a [notebook in Cortana Gallery](https://gallery.cortanaintelligence.com/Notebook/Medical-Image-Recognition-for-the-Kaggle-Data-Science-Bowl-2017-with-CNTK-and-LightGBM-1) and as a [script in Kaggle](https://www.kaggle.com/hoaphumanoid/data-science-bowl-2017/cntk-and-lightgbm-quick-start/).  \n",
    "\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The Azure Data Science Virtual Machine (DSVM) comes with CNTK, LightGBM, OpenCV, Scikit-learn preinstalled, so you don't have to worry about the configuration. \n",
    "\n",
    "Apart from the libraries, we are going to use a pretrained convolutional neural network (CNN) with the [ResNet architecture](https://arxiv.org/abs/1512.03385). This configuration, developed by Microsoft Research, was the first CNN to surpass the human level performance in image classification. The network was trained in the [ImageNet dataset](http://image-net.org/) and can be downloaded [here](https://migonzastorage.blob.core.windows.net/deep-learning/models/cntk/imagenet/ResNet_152.model).\n",
    "\n",
    "\n",
    "## Data\n",
    "In addition to the libraries you have to download the [data](https://www.kaggle.com/c/data-science-bowl-2017/data) of the competition. The images are in [DICOM](https://en.wikipedia.org/wiki/DICOM) format and consist of a group of horizontal slices of the thorax for each patient. This is a 3D reconstruction of a sample lung with the competition data. It was computed with this [script](https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial).Â  \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://migonzastorage.blob.core.windows.net/projects/data_science_bowl_2017/lung_bright.png\" alt=\"sample\" width=\"40%\"/>\n",
    "</p>\n",
    "\n",
    "The biggest file `stage1.7z` occupies 67Gb. When the file is uncompressed it occupies 141Gb. In case you need more space, you ca easily attach an external drive to your Azure VM. Here you can find the instructions for [Linux](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-attach-disk-portal?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json). An alternative route is to attach a [fileshare disk](https://docs.microsoft.com/en-us/azure/storage/storage-how-to-use-files-linux). With [this script](https://github.com/miguelgfierro/scripts/blob/master/mount_azure_fileshare.sh) the fileshare can be attached in seconds in an Azure DSMV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import dicom\n",
    "import glob\n",
    "from sklearn import cross_validation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from cntk import load_model\n",
    "from cntk.ops import combine\n",
    "import pkg_resources\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from scipy.stats import gmean\n",
    "\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"CNTK version: {}\".format(pkg_resources.get_distribution(\"cntk\").version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Function definition\n",
    "\n",
    "The first step is to set the path and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Put here the number of your experiment\n",
    "EXPERIMENT_NUMBER = '0042' \n",
    "\n",
    "#Put here the path to the downloaded ResNet model\n",
    "#https://migonzastorage.blob.core.windows.net/deep-learning/models/cntk/imagenet/ResNet_152.model\n",
    "MODEL_PATH='/datadrive/pretrained_models/ResNet_152.model' \n",
    "\n",
    "#Maximum batch size for the network to evaluate. \n",
    "BATCH_SIZE=60\n",
    "\n",
    "#Number of splits in K-fold cross validation\n",
    "N_SPLITS=5 \n",
    "\n",
    "#Put here the path where you downloaded all kaggle data\n",
    "DATA_PATH='/datadrive/lung_cancer'\n",
    "\n",
    "# Path and variables\n",
    "STAGE1_LABELS = os.path.join(DATA_PATH, 'stage1_labels.csv')\n",
    "STAGE1_SAMPLE_SUBMISSION = os.path.join(DATA_PATH, 'stage1_sample_submission.csv')\n",
    "STAGE1_FOLDER = os.path.join(DATA_PATH, 'stage1')\n",
    "EXPERIMENT_FOLDER = 'features%s' % EXPERIMENT_NUMBER\n",
    "FEATURE_FOLDER = os.path.join(DATA_PATH, 'features', EXPERIMENT_FOLDER)\n",
    "if not os.path.exists(FEATURE_FOLDER): os.makedirs(FEATURE_FOLDER)\n",
    "SUBMIT_OUTPUT='submit%s.csv' % EXPERIMENT_NUMBER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a timer class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Timer class\n",
    "class Timer(object):\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "    def start(self):\n",
    "        self.start = time.clock()\n",
    "    def stop(self):\n",
    "        self.end = time.clock()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This couple of functions collect the images, perform an histogram equalization and are resized to the ImageNet standard size: `224x224`. Also, the images in ImageNet are color images, with three channels, RGB, however, the images from the data science competition are in gray scale. A quick way to adapt the cancer images to the format of ImageNet is to pack them in groups of three. That is what we are doing in the function `get_data_id`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_3d_data(path):\n",
    "    slices = [dicom.read_file(os.path.join(path, s)) for s in os.listdir(path)]\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "    return np.stack([s.pixel_array for s in slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data_id(path, plot_data=False):\n",
    "    sample_image = get_3d_data(path)\n",
    "    sample_image[sample_image == -2000] = 0\n",
    "    if plot_data:\n",
    "        f, plots = plt.subplots(4, 5, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "    batch = []\n",
    "    cnt = 0\n",
    "    dx = 40\n",
    "    ds = 512\n",
    "    for i in range(0, sample_image.shape[0] - 3, 3):\n",
    "        tmp = []\n",
    "        for j in range(3):\n",
    "            img = sample_image[i + j]\n",
    "            img = 255.0 / np.amax(img) * img\n",
    "            img = cv2.equalizeHist(img.astype(np.uint8))\n",
    "            img = img[dx: ds - dx, dx: ds - dx]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            tmp.append(img)\n",
    "\n",
    "        batch.append(tmp)\n",
    "\n",
    "        if plot_data:\n",
    "            if cnt < 20:\n",
    "                plots[cnt // 5, cnt % 5].axis('off')\n",
    "                tmp = np.array(tmp)\n",
    "                plots[cnt // 5, cnt % 5].imshow(tmp[0,:,:], cmap='gray')\n",
    "            cnt += 1\n",
    "\n",
    "    if plot_data: plt.show()\n",
    "        \n",
    "    batch = np.array(batch, dtype='int')\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the next figure, we show the complete architecture. Each patient has an arbitrary number of scan images. The images are cropped to `224x244` and packed in groups of 3, to match the format of ImageNet. They are fed to the pretrained network in k batches and then are convoluted in each internal layer, until the penultimate one. This process is preformed using CNTK. The output of the network are the features that we are going to feed to the boosted tree, programmed with LightGBM.Â  \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://migonzastorage.blob.core.windows.net:443/projects/data_science_bowl_2017/resnet_tree_lung2.png\" alt=\"sample\" width=\"60%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "In this sample experiment, we used the last layer of a pretrained ResNet network with 152 layers as featurizer to extract features. CNTK provides other pretrained networks that you can test like [AlexNet](https://www.cntk.ai/Models/AlexNet/AlexNet.model), [AlexNet with Batch Normalization](https://www.cntk.ai/Models/AlexNet/AlexNetBS.model) and [ResNet with 18 layers](https://www.cntk.ai/Models/ResNet/ResNet_18.model).  \n",
    " \n",
    "Please note the name of the last layer of pretrained network is named as `z.x` in CNTK, which should be specified when use for featurizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_extractor():\n",
    "    node_name = \"z.x\"\n",
    "    loaded_model  = load_model(MODEL_PATH)\n",
    "    node_in_graph = loaded_model.find_by_name(node_name)\n",
    "    output_nodes  = combine([node_in_graph.owner])\n",
    "    return output_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We evaluate the images in batches. When using GPU, for a small network like ResNet18, the images of the patients can be evaluated in one step. However, for a big network like ResNet 152, the memory is too high, and it doesn't fit in a K80 GPU, therefore, we split the data into chunks and evaluate them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_evaluation(model, data, batch_size=50):\n",
    "    num_items = data.shape[0]\n",
    "    chunks = np.ceil(num_items / batch_size)\n",
    "    data_chunks = np.array_split(data, chunks, axis=0)\n",
    "    feat_list = []\n",
    "    for d in data_chunks:\n",
    "        feat = model.eval(d)\n",
    "        feat_list.append(feat)\n",
    "    feats = np.concatenate(feat_list, axis=0)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This function is responsible of computing the features. For that, given a batch of images we just compute the forward propagation in the network. The resulting features are saved as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_features(verbose=False):\n",
    "    net = get_extractor()\n",
    "    for folder in glob.glob(os.path.join(STAGE1_FOLDER, '*')):\n",
    "        foldername = os.path.basename(folder)\n",
    "        foldername_npy = foldername + '.npy'\n",
    "        if os.path.isfile(os.path.join(FEATURE_FOLDER, foldername_npy)):\n",
    "            if verbose: print(\"Features in %s already computed\" % (os.path.join(FEATURE_FOLDER, foldername)))\n",
    "            continue\n",
    "        batch = get_data_id(folder)\n",
    "        if verbose:\n",
    "            print(\"Batch size:\")\n",
    "            print(batch.shape)\n",
    "        feats = batch_evaluation(net, batch, BATCH_SIZE)\n",
    "        if verbose:\n",
    "            print(feats.shape)\n",
    "            print(\"Saving features in %s\" % os.path.join(FEATURE_FOLDER, foldername))\n",
    "        np.save(os.path.join(FEATURE_FOLDER, foldername), feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform a feature engineering process. We are going to perform a dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the feature size of the network penultimante layer \n",
    "def get_feature_shape(df, verbose=True):\n",
    "    feat0 = np.load(os.path.join(FEATURE_FOLDER,'%s.npy' % str(df['id'].iloc[0]))).squeeze()\n",
    "    feat_shape = feat0.shape[1]\n",
    "    if verbose: print(\"Size of the penultimate layer (feature size): {}\".format(feat_shape))\n",
    "    return feat_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(filename, is_train, verbose=True):\n",
    "    df = pd.read_csv(filename)\n",
    "    if verbose: print(\"Training data of size {}\".format(df.shape))\n",
    "    feat_shape = get_feature_shape(df, verbose)\n",
    "    x = np.zeros((df.shape[0], feat_shape))\n",
    "    for i, id in enumerate(df['id'].tolist()):\n",
    "        feat = np.load(os.path.join(FEATURE_FOLDER,'%s.npy' % str(id))).squeeze()\n",
    "        feat_pca = PCA(n_components=1).fit_transform(feat.transpose())\n",
    "        x[i,:] = feat_pca.squeeze()\n",
    "    if is_train:\n",
    "        y = df['cancer'].as_matrix()\n",
    "    else:\n",
    "        y = None\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a custom evaluation function for LightGBM. We want to use the same metric that is used by Kaggle to compute the score in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Custom eval function expects a callable with following functions        \n",
    "def loglikelood(y_true, y_pred):\n",
    "    eval_result = log_loss(y_true, y_pred)\n",
    "    eval_name = 'log_loss'\n",
    "    is_bigger_better = False\n",
    "    return eval_name, eval_result, is_bigger_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have the features computed we can feed them in a boosted tree. Each numpy array contains the features of the images corresponding to one patient, and they are labelled as positive (the patient has cancer) or negative (the patient doesn't have cancer). We can average and flatten all the features to obtain a one dimensional vector representing one observation. The metric use in the tree optimization is logloss, there are [other metrics](https://github.com/Microsoft/LightGBM/blob/7426ac3cbd9ae27b5d734a54e5e9880623beea43/docs/Parameters.md#metric-parameters) that can be applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_lightgbm(x, y, verbose=True):\n",
    "    skf = KFold(n_splits=N_SPLITS, random_state=2048, shuffle=True)\n",
    "    clfs = []\n",
    "    if verbose: print(\"Computing LightGBM boosted tree using {} kfold cross validation\".format(N_SPLITS))\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        trn_x, val_x = x[train_index,:], x[test_index,:]\n",
    "        trn_y, val_y = y[train_index], y[test_index]\n",
    "\n",
    "        clf = LGBMRegressor(max_depth=6,\n",
    "                            num_leaves=21,\n",
    "                            n_estimators=5000,\n",
    "                            min_child_weight=30,\n",
    "                            learning_rate=0.01,\n",
    "                            nthread=24,\n",
    "                            boosting_type='gbdt',\n",
    "                            subsample=0.80,\n",
    "                            colsample_bytree=0.80,\n",
    "                            seed=42)\n",
    "\n",
    "        clf.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], verbose=verbose, eval_metric=loglikelood, early_stopping_rounds=300)\n",
    "        clfs.append(clf)\n",
    "        \n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We create a wrapper of the training function. That way we make the code extendable in case another user wants to try other training method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_training(verbose=True):\n",
    "    with Timer() as t:\n",
    "        x, y = feature_engineering(STAGE1_LABELS, is_train=True, verbose=verbose)\n",
    "        clf = train_lightgbm(x, y, verbose)\n",
    "    if verbose: print(\"Training took %.03f sec.\\n\" % t.interval)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have trained the model, we can use it to compute the results in the validation set. Again, this function is easily extendable in case a person want to use another model (always the scikit-learn interface `predict` has to be maintained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_prediction(clfs, verbose=True):\n",
    "    preds = []\n",
    "    with Timer() as t:\n",
    "        x, _ = feature_engineering(STAGE1_SAMPLE_SUBMISSION, is_train=False, verbose=verbose)\n",
    "        for clf in clfs:\n",
    "            preds.append(np.clip(clf.predict(x),0.0001,1))\n",
    "        pred = gmean(np.array(preds), axis=0)\n",
    "    if verbose: print(\"Prediction took %.03f sec.\\n\" % t.interval)        \n",
    "    df['cancer'] = pred\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We finally save the results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_results(df, verbose=True):\n",
    "    df.to_csv(SUBMIT_OUTPUT, index=False)\n",
    "    if verbose: print(\"Results saved in {}\".format(SUBMIT_OUTPUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Execution\n",
    "\n",
    "Plot an example of images with cancer. The plot shows horizontal slices of the thorax. This is the result.\n",
    "<p align=\"center\">\n",
    "<img src=\"https://migonzastorage.blob.core.windows.net/projects/data_science_bowl_2017/output_10_0.png\" alt=\"sample\" width=\"50%\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path_cancer = os.path.join(STAGE1_FOLDER, 'fe45462987bacc32dbc7126119999392')\n",
    "data_batch = get_data_id(path_cancer, False)\n",
    "print(\"Data batch size: \", data_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot example of images without cancer. This is the result:\n",
    "<p align=\"center\">\n",
    "<img src=\"https://migonzastorage.blob.core.windows.net/projects/data_science_bowl_2017/output_12_0.png\" alt=\"sample\" width=\"50%\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_no_cancer = os.path.join(STAGE1_FOLDER, 'ffe02fe7d2223743f7fb455dfaff3842')\n",
    "data_batch = get_data_id(path_no_cancer, False)\n",
    "print(\"Data batch size: \", data_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "feat = get_extractor()\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute features. Using a K80 GPU in an Azure NC24 the computation time was: `53min 7s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate features\n",
    "calc_features(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train the boosted tree. We train the tree with early stoping of 300 rounds, which means that the optimization will stop if the validation score doesn't improve for 300 rounds. You can change the parameters of the model, with `learning_rate=0.001` it took 4.2min in a NC24 machine, these are the results:\n",
    "\n",
    "```bash\n",
    "[1]\tvalid_0's l2: 0.510462\n",
    "[2]\tvalid_0's l2: 0.510327\n",
    "[3]\tvalid_0's l2: 0.510219\n",
    "...\n",
    "...\n",
    "...\n",
    "[2483]\tvalid_0's l2: 0.437271\n",
    "[2484]\tvalid_0's l2: 0.437277\n",
    "[2485]\tvalid_0's l2: 0.437267\n",
    "Early stopping, best iteration is:\n",
    "[2185]\tvalid_0's l2: 0.436964\n",
    "Training took 252.097 sec.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clfs = compute_training(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = compute_prediction(clfs)\n",
    "print(\"Results:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Save results to csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_results(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Alternative routes and improvements\n",
    "This notebook is just an example of what you can do with CNTK and LightGBM. Here we present some alternative routes that you can implement based on this script:\n",
    "\n",
    "- Use other pretrained CNNs: As previously mentioned you can try other networks like [AlexNet](https://www.cntk.ai/Models/AlexNet/AlexNet.model), [AlexNet with Batch Normalization](https://www.cntk.ai/Models/AlexNet/AlexNetBS.model) and [ResNet with 18 layers](https://www.cntk.ai/Models/ResNet/ResNet_18.model). \n",
    "- Use transfer learning using a closer domain: The CNN we use is trained in ImageNet, which are natural images. There is another dataset called [LUNA](https://luna16.grand-challenge.org/) that you can use to train a network and then perform transfer learning. A trick that might speed up the convergence is to initialize the weights with a pretrained model (like we are doing in the notebook). \n",
    "- Perform image augmentation: You can try to increment the training set by performing transformations in the images. For that you can apply different filters or rotate them.\n",
    "- Use a customize network with 3D images: CNTK allows [3D convolutions](https://github.com/Microsoft/CNTK/wiki/Convolution). On GPU, 1D, 2D and 3D convolutions will use cuDNN (fast), all other convolutions will use reference engine (slow). You can create a CNN that accepts 3D images. \n",
    "- Try tunning the parameters of the boosted tree: You can try to tune the parameters of the tree. For that LightGBM implements the sklearn function `GridSearchCV`. Here you have an [example](https://github.com/Microsoft/LightGBM/blob/b0f7aa508a373b16adbda6cbe66b188a014964d8/examples/python-guide/sklearn_example.py).\n",
    "- Try some feature engineering: Before training the tree, the features are transformed. You can try to feed the tree without this operation or try a different one.\n",
    "\n",
    "After the competition was finished, some of the top performers published their solutions.\n",
    "\n",
    "- **Second place solution**: Julian de Wit was able to get to the second place in the Kaggle competition. Here you can find his [blog](http://juliandewit.github.io/kaggle-ndsb2017/) and here his [code](https://github.com/juliandewit/kaggle_ndsb2017). The solution is based on nodule detectors with a 3D convolutional neural network architecture.\n",
    "- **Ninth place solution**: A team composed by Andreas Verleysen, Elias Vansteenkiste, FrÃ©deric Godin, Ira Korshunova, Jonas Degrave, Lionel Pigou and Matthias Freiberger, all PhD students and postdocs at Ghent University, were able to reach the ninth position. They published a [blog](https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/) and the [code](https://github.com/EliasVansteenkiste/dsb3). The pipeline has a 3D CNN for nodule segmentation, one CNN for false positive reduction, another CNN for identifying if the nodule is malignant or not, then transfer learning and finally ensembling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Acknowledgements\n",
    "\n",
    "This notebook is based on this [script published in kaggle](https://www.kaggle.com/hoaphumanoid/data-science-bowl-2017/cntk-and-lightgbm-quick-start). It was also based in this [other script](https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57). "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
