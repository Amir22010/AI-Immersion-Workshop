{"nbformat_minor": 2, "cells": [{"source": "# III - Scoring the Trained Model", "cell_type": "markdown", "metadata": {}}, {"source": "Once the model is trained on Azure Batch Shipyard, it can be retrieved from blob storage and used to score unseen data\n* [Setup](#section1)\n* [Downloading the trained model](#section2)\n* [Loading the trained model in memory](#section3)\n* [Scoring unseen images](#section4)\n* [Test with your own image](#section5)\n* [Scoring at scale on Batch Shipyard](#section6)", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "## Setup", "cell_type": "markdown", "metadata": {}}, {"source": "Install the tqdm progress bar utility", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "!pip install tqdm", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Create alias for shipyard", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%alias shipyard SHIPYARD_CONFIGDIR=config python $HOME/batch-shipyard/shipyard.py %l", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Check that everything is working", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "shipyard", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Imports, configuration and constants", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%matplotlib inline\n\nimport random\nimport json\nfrom math import sqrt\nimport cntk\nimport os\nfrom PIL import Image\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom IPython.core.display import HTML\nfrom tqdm import tqdm\nimport xml\nimport pickle\n\nHTML(\"\"\"<style>.output_png {display: table-cell;text-align: right;vertical-align: middle;}<\/style>\"\"\")\n\n# Downloading assets\nMODEL = 'ConvNet_CIFAR10_model.dnn'\nMODEL_FOLDER = 'models'\nIMAGE_FOLDER = 'images'\nMODEL_PATH = os.path.join(MODEL_FOLDER, MODEL)\n\n# Assets for scoring on the notebook\nLOCAL_MEAN_FILE = 'mean.xml'\nLOCAL_TEST_BATCH = 'test_batch.pickle'\nURL_FMT = 'https://{}.blob.core.windows.net/{}/{}'\n\ndef select_random_data_storage_container():\n    \"\"\"Randomly select a storage account and container for CNTK model/test data.\n    This is specific for the workshop to help distribute attendee load. This\n    function will only work on Python2\"\"\"\n    ss = random.randint(0, 4)\n    cs = random.randint(0, 4)\n    sa = '{}{}bigai'.format(ss, chr(ord('z') - ss))\n    cont = '{}{}{}'.format(cs, chr(ord('i') - cs * 2), chr(ord('j') - cs * 2))\n    return sa, cont\n\nsa, cont = select_random_data_storage_container()\nMEAN_IMAGE_URI = URL_FMT.format(sa, cont, LOCAL_MEAN_FILE)\nsa, cont = select_random_data_storage_container()\nTEST_BATCH_URI = URL_FMT.format(sa, cont, LOCAL_TEST_BATCH)\nsa, cont = select_random_data_storage_container()\nPRETRAINED_MODEL_URI = URL_FMT.format(sa, cont, MODEL)\n\n# Shipyard task\nIMAGE_NAME = \"masalvar/cntkcifar\"\n\n# Loading the configuration from setup notebook\nCONFIG_FILE = 'account_information.json'\nwith open(CONFIG_FILE, 'r') as f:\n    config = json.load(f)\n    \nSTORAGE_ACCOUNT_NAME = config['storage_account_name']\nSTORAGE_ACCOUNT_KEY = config['storage_account_key']\n\nSTORAGE_ACCOUNT_ALIAS = 'mystorageaccount'\n\n# Utility function\ndef write_json_to_file(json_dict, filename):\n    \"\"\" Simple function to write JSON dictionaries to files\n    \"\"\"\n    with open(filename, 'w') as outfile:\n        json.dump(json_dict, outfile)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# Creating the folder for the trained models\n!rm -rf $MODEL_FOLDER $IMAGE_FOLDER\n!mkdir -p $MODEL_FOLDER\n!mkdir -p $IMAGE_FOLDER", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Downloading the trained model\nIf the model we trained is available in blob, we download it. Otherwise we download a pre-trained model to avoid waiting for the training to complete. First, let's alias `blobxfer` to simplify transfers rather than using the Azure CLI.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%alias blobxfer python -m blobxfer", "outputs": [], "metadata": {"collapsed": true}}, {"source": "We will attempt to download the model from the storage account. `blobxfer` will complete successfully with exit code of 0 if the model exists.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "blobxfer $STORAGE_ACCOUNT_NAME output $MODEL_FOLDER --remoteresource . --include \"*_cntk-training-job/*.dnn\" --download --storageaccountkey $STORAGE_ACCOUNT_KEY", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# if blobxfer did not exit successfully (no model found), then download a pre-trained model from public blob instead\nif _exit_code != 0:\n    print(\"Downloading pre-trained model from public blob\")\n    !wget -O $MODEL_FOLDER/$MODEL $PRETRAINED_MODEL_URI\nelse:\n    print(\"Downloaded model from prior notebook training run\")\n    !mv $MODEL_FOLDER/*_cntk-training-job/*.dnn $MODEL_FOLDER\n    !rm -rf $MODEL_FOLDER/*_cntk-training-job", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The model has been downloaded on the environment of the notebook and is ready to use", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "!ls -alF $MODEL_FOLDER", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Loading the trained model in memory\n\nThe model is expecting CIFAR-10 type images, i.e. RGB images with dimensions 32x32", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# model dimensions\nIMAGE_HEIGHT = 32\nIMAGE_WIDTH = 32\nNUM_CHANNELS = 3\nNUM_CLASSES = 10\n# Class labels in order\nLABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "model = cntk.load_model(MODEL_PATH)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Scoring unseen images", "cell_type": "markdown", "metadata": {}}, {"source": "We download some unseen test data", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "!wget $MEAN_IMAGE_URI -O $LOCAL_MEAN_FILE\n!wget $TEST_BATCH_URI -O $LOCAL_TEST_BATCH", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Process the mean image, as a pre-processing step applied to the images to score", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "mean_image = xml.etree.ElementTree.parse(LOCAL_MEAN_FILE).getroot()\nmean_image = [float(i) for i in mean_image.find('MeanImg').find('data').text.strip().split(' ')]\nmean_image = np.array(mean_image).reshape((32, 32, 3)).transpose((2, 0, 1))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Utility functions to help loading and scoring images", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def load_image(filepath):\n    \"\"\" \n    Loading the image and resizing it to match\n    the expected format from the network\n    \"\"\"\n    img = Image.open(filepath)\n    img.load()\n    wpercent = (IMAGE_WIDTH/float(img.size[0]))\n    hsize = int((float(img.size[1])*float(wpercent)))\n    img = img.resize((IMAGE_WIDTH,hsize), Image.ANTIALIAS)\n    return img\n\ndef get_predicted_label(model, img, mean_image): \n    \"\"\" \n    Perform a forward pass on the network\n    and return the predicted label\n    \"\"\"\n    # Convert image to array\n    img = np.asarray(img, dtype=\"float32\")\n    # Add padding to be 32x32\n    img = np.lib.pad(img, ((IMAGE_WIDTH-img.shape[0],0),(IMAGE_HEIGHT-img.shape[1],0),(0,0)), 'constant', constant_values=(0))\n    # Transpose from 32x32x3 to 3x32x32\n    img = np.transpose(img, (2, 0, 1))\n    img -= mean_image\n    \n    # Forward pass\n    out = model.forward(img)\n    \n    # Getting the predicted label\n    predictions = out[1].values()[0][0]\n    selected_label = LABELS[predictions.argmax()]\n    return selected_label", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Loading 10000 unseen images from a pickled file", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def reshape_image(record):\n    image, label, filename = record\n    return image.reshape(3,32,32).transpose(1,2,0), label, filename", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "with open(LOCAL_TEST_BATCH, 'r') as f:\n    test_batch = pickle.load(f)\nrecords = zip(test_batch['data'], test_batch['labels'], test_batch['filenames'])\nrecords = map(reshape_image, records)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Scoring the images in turn and displaying the results", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "m = 6\n\n# Creating a grid of m by m plots\nf, axarr = plt.subplots(m, m)\nf.set_size_inches(m*2, m*2)\nf.suptitle(\"Scoring {} images [predicted|success]\".format(m*m))\n\n# Scoring each image and plotting it in the grid\n# with the label as a title\nrandom.shuffle(records)\nfor i in range(m):\n    for j in range(m):\n        img = records[i*m+j][0]\n        label = get_predicted_label(model, img, mean_image)\n        axarr[i, j].set_title(\"{}|{}\".format(label, label==LABELS[records[i*m+j][1]]))\n        axarr[i, j].axis('off')\n        axarr[i, j].imshow(img)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Test with your own image\n\nUpload an image, of one of the 10 labels, using the `Data` > `Upload...` menu in the tool bar", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "image_name = \"<YOUR_IMAGE_NAME.PNG>\"", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Process the image", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "img = load_image(image_name)\nlabel = get_predicted_label(model, img, mean_image)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Display the result", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "img = Image.open(image_name)\nimg.load()\nf = plt.figure()\nplt.imshow(img)\nplt.title(label)\nplt.axis(\"off\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Scoring at scale on batch-shipyard", "cell_type": "markdown", "metadata": {}}, {"source": "Running locally on the notebook", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "result = []\nfor record in tqdm(records):\n    label = get_predicted_label(model, record[0], mean_image)\n    result.append(label)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "It is pretty fast... can we do better on Batch Shipyard?\n\nLet's first write a driver file that will perform the scoring and upload everything we need on our storage account", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%writefile score.py\nimport os\nimport json\nimport cntk\nimport numpy as np \nimport xml\nimport pickle\nimport time\n\ntic = time.time()\n\n# model dimensions\nIMAGE_HEIGHT = 32\nIMAGE_WIDTH = 32\nNUM_CHANNELS = 3\nNUM_CLASSES = 10\n\nMODEL_PATH = 'ConvNet_CIFAR10_model.dnn'\nLOCAL_MEAN_FILE = 'mean.xml'\nLOCAL_TEST_BATCH = 'test_batch.pickle'\n\ndef reshape_image(record):\n    image, label, filename = record\n    return image.reshape(3,32,32).transpose(1,2,0), label, filename\n\ndef get_predicted_label(model, img, mean_image): \n    \"\"\" \n    Perform a forward pass on the network\n    and return the predicted label\n    \"\"\"\n    # Convert image to array\n    img = np.asarray(img, dtype=\"float32\")\n    # Add padding to be 32x32\n    img = np.lib.pad(img, ((IMAGE_WIDTH-img.shape[0],0),(IMAGE_HEIGHT-img.shape[1],0),(0,0)), 'constant', constant_values=(0))\n    # Transpose from 32x32x3 to 3x32x32\n    img = np.transpose(img, (2, 0, 1))\n    img -= mean_image\n    \n    # Forward pass\n    out = model.forward(img)\n    \n    # Getting the predicted label\n    predictions = list(out[1].values())[0][0]\n    return predictions.argmax()\n\n\n# Loading the model\nmodel = cntk.load_model(MODEL_PATH)\n\n# Loading the mean image\nmean_image = xml.etree.ElementTree.parse(LOCAL_MEAN_FILE).getroot()\nmean_image = [float(i) for i in mean_image.find('MeanImg').find('data').text.strip().split(' ')]\nmean_image = np.array(mean_image).reshape((32, 32, 3)).transpose((2, 0, 1))\n\n# Loading the images\nwith open(LOCAL_TEST_BATCH, 'rb') as f:\n    u = pickle._Unpickler(f)\n    u.encoding = 'latin1'\n    test_batch = u.load()\nrecords = zip(test_batch['data'], test_batch['labels'], test_batch['filenames'])\nrecords = map(reshape_image, records)\n\nresult = []\ni = 0\nfor record in records:\n    if i % 1000 == 0:\n        print(\"processed {} records\".format(i))\n    i+=1\n    label = get_predicted_label(model, record[0], mean_image)\n    # convert label type numpy.int64 to python int\n    result.append((label.item(), record[1], record[2]))\n\ntoc = time.time()\nprint(\"{} seconds elapsed to process {} records\".format(toc-tic, i))\n\nwith open('results.json', 'w') as f:\n    json.dump(result, f)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Let's upload all of the data we need to ingress in the batch task:\n- the mean file\n- the image data file\n- the trained model\n- the python driver, score.py\n\nLet's designate the containers to use for input and output and then copy all of the input data into one directory to upload via blobxfer to the `INPUT_CONTAINER`:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "INPUT_CONTAINER = \"inputscore\"\nOUTPUT_CONTAINER = \"outputscore\"\n\nUPLOAD_DIR = 'input_upload'\n\n!mkdir -p $UPLOAD_DIR\n!cp $LOCAL_TEST_BATCH $LOCAL_MEAN_FILE $MODEL_PATH score.py $UPLOAD_DIR\n!ls -alF $UPLOAD_DIR", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Upload via `blobxfer` to the `INPUT_CONTAINER`:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "blobxfer $STORAGE_ACCOUNT_NAME $INPUT_CONTAINER $UPLOAD_DIR --upload --storageaccountkey $STORAGE_ACCOUNT_KEY", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Now let's create the jobs json specification. The task will first activate cntk and then run the scoring script.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "JOB_ID = 'cntk-scoring-job'\n\nCOMMAND = 'bash -c \"source /cntk/activate-cntk; python -u score.py\"'\n\njobs = {\n    \"job_specifications\": [\n        {\n            \"id\": JOB_ID,\n            \"tasks\": [\n                {\n                    \"image\": IMAGE_NAME,\n                    \"remove_container_after_exit\": True,\n                    \"command\": COMMAND,\n                    \"gpu\": True,\n                    \"output_data\": {\n                        \"azure_storage\": [\n                            {\n                                \"storage_account_settings\": STORAGE_ACCOUNT_ALIAS,\n                                \"container\": OUTPUT_CONTAINER,\n                                \"include\": [\"*.json\"],\n                                \"blobxfer_extra_options\": \"--delete --strip-components 2\"\n                            }\n                        ]\n                    },\n                    \"input_data\": {\n                        \"azure_storage\": [\n                            {\n                                \"storage_account_settings\": STORAGE_ACCOUNT_ALIAS,\n                                \"container\": INPUT_CONTAINER\n                            }\n                        ]\n                    },\n                }\n            ],\n        }\n    ]\n}", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "write_json_to_file(jobs, os.path.join('config', 'jobs.json'))\nprint(json.dumps(jobs, indent=4, sort_keys=True))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Now that the specification for the jobs is written, we add the task to batch shipyard", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "shipyard jobs add --tail stdout.txt", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We can see the total duration of the time taken for the task with the command:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "shipyard jobs listtasks --jobid $JOB_ID", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We can retrieve the results from the executed task from the `OUTPUT_CONTAINER`:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "blobxfer $STORAGE_ACCOUNT_NAME $OUTPUT_CONTAINER $MODEL_FOLDER --download --remoteresource results.json --storageaccountkey $STORAGE_ACCOUNT_KEY", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "!ls -alF $MODEL_FOLDER", "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Note:** we could have used the `shipyard data getfile` command to retrieve the `results.json` file directly from the compute node if we did not need to persist the results to Azure Storage and the compute node is still running.\n\nNow that we are done with the scoring job, delete it:", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "shipyard jobs del -y --termtasks --wait", "outputs": [], "metadata": {"collapsed": false}}, {"source": "[Next notebook: Parametric Sweep](04_Parameter_Sweep.ipynb)", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}